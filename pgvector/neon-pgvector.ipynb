{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vector similarity search using Neon Postgres with pgvector and OpenAI\n",
    "\n",
    "This notebook guides you through using [Neon Serverless Postgres](https://neon.tech/) as a vector database for OpenAI embeddings. It demonstrates how to:\n",
    "\n",
    "1. Use embeddings created by OpenAI API\n",
    "2. Store embeddings in a Neon Serverless Postgres database\n",
    "3. Convert a raw text query to an embedding with OpenAI API\n",
    "4. Use Neon with the `pgvector` extension to perform vector similarity search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "Before you begin, ensure that you have the following:\n",
    "\n",
    "1. A Neon Postgres database. You can create an account and set up a project with a ready-to-use `neondb` database in a few simple steps. For instructions, see [Sign up](https://neon.tech/docs/get-started-with-neon/signing-up) and [Create your first project](https://neon.tech/docs/get-started-with-neon/setting-up-a-project).\n",
    "2. A connection string for your Neon database. You can copy it from the **Connection Details** widget on the Neon **Dashboard**. See [Connect from any application](https://neon.tech/docs/connect/connect-from-any-app).\n",
    "3. The `pgvector` extension. Install the extension in Neon by running `CREATE EXTENSION vector;`. For instructions, see [Enable the pgvector extension](https://neon.tech/docs/extensions/pgvector#enable-the-pgvector-extension). \n",
    "4. Your [OpenAI API key](https://platform.openai.com/account/api-keys).\n",
    "5. Python and `pip`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install required modules\n",
    "\n",
    "This notebook requires the `openai`, `psycopg2`, `pandas`, `wget`, and `python-dotenv` packages. You can install them with `pip`:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in /opt/homebrew/lib/python3.11/site-packages (0.27.7)\n",
      "Collecting psycopg2\n",
      "  Downloading psycopg2-2.9.7.tar.gz (383 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m383.5/383.5 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: pandas in /opt/homebrew/lib/python3.11/site-packages (1.3.5)\n",
      "Collecting wget\n",
      "  Downloading wget-3.2.zip (10 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: python-dotenv in /opt/homebrew/lib/python3.11/site-packages (1.0.0)\n",
      "Requirement already satisfied: requests>=2.20 in /opt/homebrew/lib/python3.11/site-packages (from openai) (2.28.2)\n",
      "Requirement already satisfied: tqdm in /opt/homebrew/lib/python3.11/site-packages (from openai) (4.65.0)\n",
      "Requirement already satisfied: aiohttp in /opt/homebrew/lib/python3.11/site-packages (from openai) (3.8.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /opt/homebrew/lib/python3.11/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /opt/homebrew/lib/python3.11/site-packages (from pandas) (2023.2)\n",
      "Requirement already satisfied: numpy>=1.21.0 in /opt/homebrew/lib/python3.11/site-packages (from pandas) (1.24.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/homebrew/lib/python3.11/site-packages (from python-dateutil>=2.7.3->pandas) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/homebrew/lib/python3.11/site-packages (from requests>=2.20->openai) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/homebrew/lib/python3.11/site-packages (from requests>=2.20->openai) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/homebrew/lib/python3.11/site-packages (from requests>=2.20->openai) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/homebrew/lib/python3.11/site-packages (from requests>=2.20->openai) (2022.12.7)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/homebrew/lib/python3.11/site-packages (from aiohttp->openai) (22.2.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/homebrew/lib/python3.11/site-packages (from aiohttp->openai) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/homebrew/lib/python3.11/site-packages (from aiohttp->openai) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/homebrew/lib/python3.11/site-packages (from aiohttp->openai) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/homebrew/lib/python3.11/site-packages (from aiohttp->openai) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/homebrew/lib/python3.11/site-packages (from aiohttp->openai) (1.3.1)\n",
      "Building wheels for collected packages: psycopg2, wget\n",
      "  Building wheel for psycopg2 (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for psycopg2: filename=psycopg2-2.9.7-cp311-cp311-macosx_13_0_arm64.whl size=145725 sha256=6504c3b3cd428e1fc64e2e4de815bc360b47553ef7aa1e3aeedbf7cd59a92bc3\n",
      "  Stored in directory: /Users/betuloreilly/Library/Caches/pip/wheels/ca/a2/1f/9f85470e2065e7a4089baa6c47cfa57a2f8f8e78e07390c5b4\n",
      "  Building wheel for wget (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9655 sha256=8b3f18262fa8a0aa7f77783115d8a774ab59bf2ab3b388d9f6eda29bc93dc6d3\n",
      "  Stored in directory: /Users/betuloreilly/Library/Caches/pip/wheels/40/b3/0f/a40dbd1c6861731779f62cc4babcb234387e11d697df70ee97\n",
      "Successfully built psycopg2 wget\n",
      "Installing collected packages: wget, psycopg2\n",
      "Successfully installed psycopg2-2.9.7 wget-3.2\n"
     ]
    }
   ],
   "source": [
    "! pip install openai psycopg2 pandas wget python-dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare your OpenAI API key\n",
    "\n",
    "An OpenAI API key is required to generate vectors for documents and queries.\n",
    "\n",
    "If you do not have an OpenAI API key, obtain one from https://platform.openai.com/account/api-keys.\n",
    "\n",
    "Add the OpenAI API key as an operating system environment variable. Name the variable `OPENAI_API_KEY`.\n",
    "\n",
    "For information about configuring your OpenAI API key as an environment variable, refer to [Best Practices for API Key Safety](https://help.openai.com/en/articles/5112595-best-practices-for-api-key-safety)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test your OpenAPI key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your OPENAI_API_KEY is ready\n"
     ]
    }
   ],
   "source": [
    "# Test to ensure that your OpenAI API key is defined as an environment variable\n",
    "# If you run this notebook locally, you may have to reload the terminal and the notebook to make the environment available\n",
    "\n",
    "import os\n",
    "\n",
    "if os.getenv(\"OPENAI_API_KEY\") is not None:\n",
    "    print(\"Your OPENAI_API_KEY is ready\")\n",
    "else:\n",
    "    print(\"Your OPENAI_API_KEY environment variable was not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to your Neon database\n",
    "\n",
    "Provide your Neon database connection string below or define it in an `.env` file using a `DATABASE_URL` variable. For information about obtaining a Neon connection string, see [Connect from any application](https://neon.tech/docs/connect/connect-from-any-app)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import psycopg2\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# The connection string can be provided directly here.\n",
    "# Replace the next line with Your Neon connection string.\n",
    "connection_string = \"\"\n",
    "\n",
    "# If connection_string is not directly provided above, \n",
    "# then check if DATABASE_URL is set in the environment or .env.\n",
    "if not connection_string:\n",
    "    connection_string = os.environ.get(\"DATABASE_URL\")\n",
    "\n",
    "    # If neither method provides a connection string, raise an error.\n",
    "    if not connection_string:\n",
    "        raise ValueError(\"Please provide a valid connection string either in the code or in the .env file as DATABASE_URL.\")\n",
    "\n",
    "# Connect using the connection string\n",
    "connection = psycopg2.connect(connection_string)\n",
    "\n",
    "# Create a new cursor object\n",
    "cursor = connection.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the connection to your database:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your database connection was successful!\n"
     ]
    }
   ],
   "source": [
    "# Execute this query to test the database connection\n",
    "cursor.execute(\"SELECT 1;\")\n",
    "result = cursor.fetchone()\n",
    "\n",
    "# Check the query result\n",
    "if result == (1,):\n",
    "    print(\"Your database connection was successful!\")\n",
    "else:\n",
    "    print(\"Your connection failed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a table and add indexes for your vector embeddings\n",
    "\n",
    "The vector table created in your database is called **articles**. Each object has **title** and **content** vectors. \n",
    "\n",
    "An index is defined on both the **title** and **content** vector columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_table_sql = '''\n",
    "CREATE TABLE IF NOT EXISTS public.articles (\n",
    "    id INTEGER NOT NULL,\n",
    "    url TEXT,\n",
    "    title TEXT,\n",
    "    content TEXT,\n",
    "    title_vector vector(1536),\n",
    "    content_vector vector(1536),\n",
    "    vector_id INTEGER\n",
    ");\n",
    "\n",
    "ALTER TABLE public.articles ADD PRIMARY KEY (id);\n",
    "'''\n",
    "\n",
    "# SQL statement for creating indexes\n",
    "create_indexes_sql = '''\n",
    "CREATE INDEX ON public.articles USING ivfflat (content_vector) WITH (lists = 1000);\n",
    "\n",
    "CREATE INDEX ON public.articles USING ivfflat (title_vector) WITH (lists = 1000);\n",
    "'''\n",
    "\n",
    "# Execute the SQL statements\n",
    "cursor.execute(create_table_sql)\n",
    "cursor.execute(create_indexes_sql)\n",
    "\n",
    "# Commit the changes\n",
    "connection.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data\n",
    "\n",
    "Load the pre-computed vector data into your `articles` table from the `.csv` file. There are 25000 records, so expect the operation to take several minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "\n",
    "# Path to your local CSV file\n",
    "csv_file_path = '/Users/betuloreilly/vectordata/test4.csv'\n",
    "\n",
    "# Define a generator function to process the csv file\n",
    "def process_file(file_path):\n",
    "    with open(file_path, 'r', encoding='ISO-8859-1') as file:\n",
    "        for line in file:\n",
    "            yield line\n",
    "\n",
    "# Create a StringIO object to store the modified lines\n",
    "modified_lines = io.StringIO(''.join(list(process_file(csv_file_path))))\n",
    "\n",
    "# Create the COPY command for copy_expert\n",
    "copy_command = '''\n",
    "COPY public.articles (id, url, title, content, title_vector, content_vector, vector_id)\n",
    "FROM STDIN WITH (FORMAT CSV, HEADER true, DELIMITER ';');\n",
    "'''\n",
    "\n",
    "# Execute the COPY command using copy_expert\n",
    "cursor.copy_expert(copy_command, modified_lines)\n",
    "\n",
    "# Commit the changes\n",
    "connection.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the number of records to ensure the data has been been loaded. There should be 25000 records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count:40\n"
     ]
    }
   ],
   "source": [
    "# Check the size of the data\n",
    "count_sql = \"\"\"select count(*) from public.articles;\"\"\"\n",
    "cursor.execute(count_sql)\n",
    "result = cursor.fetchone()\n",
    "print(f\"Count:{result[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search your data\n",
    "\n",
    "After the data is stored in your Neon database, you can query the data for nearest neighbors. \n",
    "\n",
    "A `vector_name` parameter is provided that allows you to search based on \"title\" or \"content\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_neon(query, collection_name, vector_name=\"title_vector\", top_k=20):\n",
    "\n",
    "    # Create an embedding vector from the user query\n",
    "    embedded_query = openai.Embedding.create(\n",
    "        input=query,\n",
    "        model=\"text-embedding-ada-002\",\n",
    "    )[\"data\"][0][\"embedding\"]\n",
    "\n",
    "    # Convert the embedded_query to PostgreSQL compatible format\n",
    "    embedded_query_pg = \"[\" + \",\".join(map(str, embedded_query)) + \"]\"\n",
    "\n",
    "    # Create the SQL query\n",
    "    query_sql = f\"\"\"\n",
    "    SELECT id, url, title, l2_distance({vector_name},'{embedded_query_pg}'::VECTOR(1536)) AS similarity\n",
    "    FROM {collection_name}\n",
    "    ORDER BY {vector_name} <-> '{embedded_query_pg}'::VECTOR(1536)\n",
    "    LIMIT {top_k};\n",
    "    \"\"\"\n",
    "    # Execute the query\n",
    "    cursor.execute(query_sql)\n",
    "    results = cursor.fetchall()\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run a similarity search based on `title_vector` embeddings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Astronomy (Score: 0.412)\n",
      "2. Anatomy (Score: 0.409)\n",
      "3. Archaeology (Score: 0.404)\n",
      "4. Art (Score: 0.391)\n",
      "5. Asteroid (Score: 0.382)\n",
      "6. Abrahamic religion (Score: 0.371)\n",
      "7. Algebra (Score: 0.369)\n",
      "8. Architecture (Score: 0.359)\n",
      "9. Native American (Score: 0.359)\n",
      "10. Farming (Score: 0.356)\n",
      "11. Australia (Score: 0.353)\n",
      "12. Application (Score: 0.35)\n",
      "13. Armenia (Score: 0.342)\n",
      "14. Animal (Score: 0.341)\n",
      "15. Atom (Score: 0.339)\n",
      "16. Arithmetic (Score: 0.338)\n",
      "17. April (Score: 0.335)\n",
      "18. Alan Turing (Score: 0.33)\n",
      "19. August (Score: 0.329)\n",
      "20. Austria (Score: 0.329)\n"
     ]
    }
   ],
   "source": [
    "# Query based on `title_vector` embeddings\n",
    "import openai\n",
    "\n",
    "query_results = query_neon(\"Greek mythology\", \"Articles\")\n",
    "for i, result in enumerate(query_results):\n",
    "    print(f\"{i + 1}. {result[2]} (Score: {round(1 - result[3], 3)})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run a similarity search based on `content_vector` embeddings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Astronomy (Score: 0.277)\n",
      "2. Angel (Score: 0.265)\n",
      "3. Australia (Score: 0.262)\n",
      "4. A (Score: 0.257)\n",
      "5. April (Score: 0.256)\n",
      "6. August (Score: 0.254)\n",
      "7. Atom (Score: 0.251)\n",
      "8. Ad hominem (Score: 0.25)\n",
      "9. Archaeology (Score: 0.248)\n",
      "10. Architecture (Score: 0.247)\n",
      "11. Alan Turing (Score: 0.243)\n",
      "12. Austria (Score: 0.239)\n",
      "13. Afghanistan (Score: 0.236)\n",
      "14. Armenia (Score: 0.235)\n",
      "15. Farming (Score: 0.235)\n",
      "16. Argentina (Score: 0.234)\n",
      "17. Autonomous communities of Spain (Score: 0.234)\n",
      "18. Abbreviation (Score: 0.232)\n",
      "19. Anatomy (Score: 0.232)\n",
      "20. Algebra (Score: 0.231)\n"
     ]
    }
   ],
   "source": [
    "# Query based on `content_vector` embeddings\n",
    "query_results = query_neon(\"Famous battles in Greek history\", \"Articles\", \"content_vector\")\n",
    "for i, result in enumerate(query_results):\n",
    "    print(f\"{i + 1}. {result[2]} (Score: {round(1 - result[3], 3)})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Arithmetic (Score: 0.998)\n",
      "2. Algebra (Score: 0.58)\n",
      "3. Addition (Score: 0.453)\n",
      "4. Astronomy (Score: 0.42)\n",
      "5. Farming (Score: 0.418)\n",
      "6. Art (Score: 0.417)\n",
      "7. Application (Score: 0.41)\n",
      "8. Anatomy (Score: 0.405)\n",
      "9. Architecture (Score: 0.388)\n",
      "10. Acceleration (Score: 0.37)\n",
      "11. Atom (Score: 0.363)\n",
      "12. A (Score: 0.359)\n",
      "13. Alan Turing (Score: 0.359)\n",
      "14. Archaeology (Score: 0.358)\n",
      "15. Armenia (Score: 0.355)\n",
      "16. Ad hominem (Score: 0.355)\n",
      "17. August (Score: 0.354)\n",
      "18. Adobe Illustrator (Score: 0.345)\n",
      "19. Abbreviation (Score: 0.345)\n",
      "20. Abrahamic religion (Score: 0.343)\n"
     ]
    }
   ],
   "source": [
    "# Query based on `title_vector` embeddings\n",
    "import openai\n",
    "\n",
    "query_results = query_neon(\"Arithmetic\", \"Articles\")\n",
    "for i, result in enumerate(query_results):\n",
    "    print(f\"{i + 1}. {result[2]} (Score: {round(1 - result[3], 3)})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
